---
layout: post
title:  "Newton, Quasi-Newton, dan L-BFGS Optimization"
date: 2018-01-07 20:10 +1300
categories: Optimization
published: false
---

*Mathematical optimization* merupakan studi tentang mencari nilai ekstrem (minimum atau maksimum) dari sebuah fungsi $f: \mathbb{R}^m \rightarrow \mathbb{R}$, yang dapat diekspresikan dengan

\begin{equation}
\label{eq:opt_prob}
\min_{x \in \mathbb{R}^m} f(x)
\end{equation}


Problem di atas menjadi maksimisasi dengan mengganti $\min$ menjadi $\max$ atau tetap menggunakan $\min$ namun dengan menegatifkan fungsi $-f(x)$ (tanpa mengurangi generalisasi tulisan ini akan berfokus pada problem minimisasi).
Bidang studi ini dapat dikatakan salah satu bidang studi matematika yang paling aplikatif.
Penggunaannya dimulai dari *engineering*, *mechanics*, *operations research*, *economics/finance* hingga *computer science*. 

Salah satu pendekatan pemecahan masalah ($\ref{eq:opt_prob}$) adalah dengan menggunakan *gradient*, dengan asumsi fungsi $f(x)$ harus memiliki turunan hingga orde tertentu (dikenal dengan istilah *smooth function*).
Kita juga perlu mengasumsikan bahwa fungsi $f(x)$ bersifat *solvable*, yaitu terdapat poin optimal $x^*$ yang memberikan nilai minimum/maksimum $f(x^*)$.
Dari kalkulus kita mengetahui bahwa syarat cukup dan perlu untuk poin $x^*$ adalah gradient dari fungsi $f(x^*)$ sama dengan 0:

\begin{equation}
\label{eq:grad_opt}
\nabla f(x^*) = 0
\end{equation}
Dengan demikian, menyelesaikan problem optimisasi ($\ref{eq:opt_prob}$) sama dengan menyelesaikan persamaan ($\ref{eq:grad_opt}$).

Secara umum terdapat 2 cara untuk menyelesaikan persamaan tersebut:f
\begin{enumerate}
\item Solusi analitis: bentuk fungsi gradient $\nabla f(x)$ diketahui dengan jelas sehingga dengan mudah mencari $x^*$ secara aljabar dengan menggunakan $\nabla f(x^*) = 0$.
\item Solusi iteratif: solusi $x$ diperbaharui berulang-ulang dengan memanfaatkan $\nabla f(x)$ sehingga $f(x)$ dekat dengan $f(x^*)$: $f(x) - f(x^*) < \epsilon$.
\end{enumerate}
Solusi iteratif biasanya diperlukan ketika solusi analitis tidak memungkinkan.
Dan pada kebanyakan kasus di dunia nyata kita tidak mampu mendapatkan solusi analitis sehingga diperlukan algoritma iteratif untuk menyelesaikan problem ($\ref{eq:opt_prob}$).

\section{Solusi iteratif}
Secara lebih detail, solusi iteratif menghasilkan sekuens solusi $x^{(0)}, x^{(1)}, \ldots, x^{(k)}$, dimana $f(x^{(k)}) \rightarrow f(x^*)$  untuk $k \rightarrow \infty$.
Untuk kasus meminimumkan fungsi $f(x)$, kita menginginkan algoritma yang mampu memenuhi persyaratan $f(x^{(t+1)}) < f(x^{(t)})$ untuk tiap iterasi $t$. 
Algoritma akan berhenti pada kondisi $f(x^{(k)}) < \varepsilon$, dimana $\varepsilon > 0$ merupakan konstanta yang kita tetapkan (*stopping criterion*).

Hubungan antara $x^{(t)}$ dan $x^{(t+1)}$ bersifat translasional sehingga kita dapat menuliskan 
\begin{equation}
x^{(t+1)} = x^{(t)} + \Delta x,
\end{equation}
dimana $\Delta x$ menyatakan seberapa jauh delta / pergeseran dari $x^{(t)}$ ke $x^{(t+1)}$.
Untuk menyederhanakan notasi, selanjutnya kita akan menuliskan $x := x^{(t)}$ dan $x^\prime := x^{(t+1)}$.
Dengan demikian kita menginginkan $f(x + \Delta x) < f(x)$.

Secara umum, bentuk algoritma iteratif untuk menyelesaikan problem optimisasi ($\ref{eq:opt_prob}$) sangat sederhana, yaitu sebagai berikut:
\begin{algorithm}[!htb]
\caption{Bentuk Umum Algoritma Optimisasi Solusi Iteratif}
\Begin{
$\mathbf{x}^{(0)} := \mathrm{initialize}()$\;
\For{$t = 1, \ldots, k$}
{
	$x^{(t)} := x^{(t-1)} + \Delta x$\;
}
}
\label{alg:iter}
\end{algorithm}

Bagaimana menentukan delta $\Delta x$ agar syarat $f(x + \Delta x) < f(x)$ terpenuhi? Alat yang dapat kita gunakan adalah Taylor Series Expansion, yang nantinya akan menggiring kita untuk sampai kepada penggunaan gradient fungsi $f(x)$.

\section{Taylor's Series Expansion}
Taylor's series merupakan ....
Dalam hal ini Taylor Series Expansion digunakan sebagai penghubung antara $f(\mathbf{x} + \Delta \mathbf{x})$ dengan $f(\mathbf{x})$.
Kita akan fokuskan pada kasus *multivariate* berdimensi $m$, yaitu jika terdapat sebuah vektor $\mathbf{x} \in \mathbb{R}^m$, maka Taylor's Series Expansion dari $f(\mathbf{x} + \Delta \mathbf{x})$ dapat ditulis dalam bentuk


\begin{equation}
\label{eq:taylor}
f(\mathbf{x} + \Delta \mathbf{x}) = f(\mathbf{x}) + \Delta \mathbf{x}^\top \nabla f(\mathbf{x}) + \frac{1}{2} \Delta \mathbf{x}^\top \nabla^2 f(\mathbf{x}) \Delta \mathbf{x} + \cdots,
\end{equation}
dimana $\nabla f(\mathbf{x})$ merupakan turunan pertama / vektor gradient dan $\nabla^2 f(\mathbf{x})$ merupakan turunan kedua / matriks Hessian dari fungsi $f(x)$.
Untuk menyederhanakan notasi, kita tulis vektor gradient dengan $\mathbf{g} := \nabla f(\mathbf{x}) \in \mathbb{R}^m$ dan matriks Hessian dengan $\mathbf{H} := \nabla^2 f(\mathbf{x}) \in \mathbb{R}^{m \times m}$.

Sedikit pengantar bagi yang belum familiar turunan pertama dan kedua terhadap variabel berdimensi $m$. 
Turunan pertama dari $f( \mathbf{x} )$ merupakan turunan parsial dari $f(\mathbf{x})$ terhadap masing-masing elemen dari vektor $\mathbf{x} = [x_1, \ldots, x_m]^\top$, sehingga hasil akhirnya berupa vektor:
% Turunan pertama dari $f{ \mathbf{x} )$, yaitu vektor , didapatkan 
% melalui turunan parsial dari $f( \mathbf{x} )$ terhadap masing-masing elemen dari vektor $\mathbf{x}$.
\begin{equation}
\mathbf{g} = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \cdots, \frac{\partial f}{\partial x_m} \right]^\top
\end{equation}
Sedangkan, turunan kedua dari $f( \mathbf{x} )$ dapat dihitung melalui turunan partial dari vektor $\mathbf{g}$ terhadap masing-masing elemen $\mathbf{x}$ sehingga hasil akhirnya berupa matriks (dikenal dengan sebutan Hessian):
\begin{equation}
\mathbf{H} = 
\begin{bmatrix}
\frac{\partial f}{\partial x_1 \partial x_1} & \frac{\partial f}{\partial x_1 \partial x_2} & \cdots & \frac{\partial f}{\partial x_1 \partial x_m} \\
\frac{\partial f}{\partial x_2 \partial x_1} & \frac{\partial f}{\partial x_2 \partial x_2} & \cdots & \frac{\partial f}{\partial x_2 \partial x_m} \\
\vdots & \cdots & \ddots & \vdots \\
\frac{\partial f}{\partial x_m \partial x_1} & \cdots & \cdots & \frac{\partial f}{\partial x_m \partial x_m}
\end{bmatrix}
\end{equation}

Kita akan gunakan Taylor series ($\ref{eq:taylor}$) untuk melakukan pendekatan terhadap $f(\mathbf{x} + \Delta \mathbf{x})$, yaitu dengan membatasinya hingga orde ke-2 saja, seperti di bawah ini:

\begin{equation}
\label{eq:taylor_appr}
f(\mathbf{x} + \Delta \mathbf{x}) \approx \underbrace{ f(\mathbf{x}) + \Delta \mathbf{x}^\top \mathbf{g} + \frac{1}{2} \Delta \mathbf{x}^\top \mathbf{H} \Delta \mathbf{x} }_{h( \Delta \mathbf{x} )}
\end{equation}

Target kita adalah mencari nilai delta $\Delta \mathbf{x}$ yang memenuhi persamaan aproksimasi di atas.
Trik yang dapat digunakan adalah dengan menghitung turunan pertama persamaan ($\ref{eq:taylor_appr}$) terhadap $\Delta \mathbf{x}$ menjadi 
\begin{equation}
\label{eq:secant}
\nabla f ( \mathbf{x} + \Delta \mathbf{x}) \approx \nabla h(\Delta \mathbf{x}) =  \mathbf{g} + \mathbf{H} \Delta \mathbf{x}
\end{equation}

Dengan mengeset $\nabla h(\Delta \mathbf{x}) = 0$, maka kita akan mendapatkan solusi dari $\Delta \mathbf{x}$:
\begin{equation}
\label{eq:deltax}
\Delta \mathbf{x} = -\mathbf{H}^{-1} \mathbf{g}
\end{equation}
Jadi, $h(\Delta x)$ akan mendekati nilai evaluasi fungsi $f(\mathbf{x} + \Delta \mathbf{x})$ apabila $\Delta \mathbf{x}$ memenuhi persamaan di atas. 
Dari sini cukup jelas peranan matriks Hessian dan vektor gradient untuk mencari solusi iteratif dari problem optimisasi ($\ref{eq:opt_prob}$), yaitu menentukan arah kemana solusi $\mathbf{x}$ harus bergerak di iterasi selanjutnya agar semakin mendekati tujuan utama.

Ada beberapa variasi algoritma iteratif yang dapat dibentuk dari persamaan ($\ref{eq:deltax}$).
Kita akan lihat algoritma-algoritma tersebut pada bagian-bagian selanjutnya.

\section{Gradient Descent}
Gradient descent merupakan bentuk yang paling simpel dari Algoritma $\ref{alg:iter}$ untuk menyelesaikan problem optimisasi berdasarkan ($\ref{eq:deltax}$).
Gradient descent hanya memanfaat informasi turunan pertama / vektor gradient dan tidak menghiraukan turunan kedua / matriks Hessian.
Dengan kata lain, matriks Hessian sama dengan matriks identitas $\mathbf{H} = \mathbf{I}$.

Agar dapat mengontrol kecepatan gradient, kita menambahkan konstanta $\alpha > 0$ (*step size*) sebagai faktor pengali dari $\mathbf{g}$.
Dengan demikian, gradient descent memiliki bentuk $\Delta \mathbf{x}$ seperti di bawah ini:
\begin{equation}
\label{eq:delta_gd}
	\Delta \mathbf{x} = - \alpha \mathbf{g}
\end{equation}
Konstanta $\alpha$ dapat ditentukan secara otomatis dengan menggunakan algoritma *line search*.
Dengan mensubstitusi $\Delta \mathbf{x}$ pada Algoritma $\ref{alg:iter}$ dengan ($\ref{eq:delta_gd}$), kita menghasilkan algoritma gradient descent sebagai berikut:
\begin{algorithm}[!htb]
\label{alg:gd}
\caption{Gradient Descent}
\Begin{
$\mathbf{x}^{(0)} := \mathrm{initialize}()$\;
\For{$t = 1, \ldots, k$}
{
	$\mathbf{d} = \mathbf{g}^{(t-1)}$\;
	$\displaystyle \alpha := \min_{\alpha > 0} f( \mathbf{x}^{(t-1)} - \alpha \mathbf{d} )$\;
	$\mathbf{x}^{(t)} := \mathbf{x}^{(t-1)} - \alpha \mathbf{d}$\;
}
}
\end{algorithm}

Dikarenakan tidak melibatkan penghitungan matriks Hessian $\mathbf{H}$, algoritma gradient descent cukup efisien untuk dieksekusi baik dari sisi waktu maupun penggunaan memori.
Namun demikian, disaat yang sama ia mengorbankan akurasi di tiap iterasinya sehingga secara keseluruhan boleh jadi membutuhkan iterasi yang lebih panjang untuk mencapai tujuan -- total waktu eksekusi yang dibutuhkan lebih lama.


\section{Metode Newton}
Jika matriks Hessian $\mathbf{H}$ diikutkan dan dihitung secara eksak

\begin{algorithm}[!htb]
\label{alg:gd}
\caption{Metode Newton}
\Begin{
$\mathbf{x}^{(0)} := \mathrm{initialize}()$\;
\For{$t = 1, \ldots, k$}
{
	$\mathbf{d} = \mathbf{H}^{-1 (t-1)} \mathbf{g}^{(t-1)}$\;
	$\displaystyle \alpha := \min_{\alpha > 0} f( \mathbf{x}^{(t-1)} - \alpha \mathbf{d})$\;
	$\mathbf{x}^{(t)} := \mathbf{x}^{(t-1)} - \alpha \mathbf{d}$\;
}
}
\end{algorithm}

\section{Metode BFGS}

\section{Metode L-BFGS}

\section{Implementasi dengan Scipy}
